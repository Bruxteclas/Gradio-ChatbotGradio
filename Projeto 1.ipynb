{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "be9b97a4-2abc-4eed-a672-0663c11e4373",
   "metadata": {},
   "source": [
    "### üìå Vis√£o Geral do Projeto  \n",
    "\n",
    "O **Gradio** √© uma biblioteca Python que facilita a cria√ß√£o de interfaces de usu√°rio para modelos de Machine Learning, processamento de texto, imagens e muito mais. Com poucas linhas de c√≥digo, podemos desenvolver uma UI interativa e compartilh√°-la via link sem necessidade de um servidor complexo.  \n",
    "\n",
    "Neste projeto, vamos construir uma aplica√ß√£o simples que usa **Gradio** para criar uma interface interativa. A aplica√ß√£o permitir√° que o usu√°rio envie um texto e receba uma resposta processada. Podemos integrar isso a um modelo de NLP, como um chatbot usando **OpenAI GPT** ou at√© mesmo aplicar transforma√ß√µes b√°sicas ao texto, como converter para mai√∫sculas.  \n",
    "\n",
    "---\n",
    "\n",
    "### üîπ **Objetivo do Projeto**  \n",
    "\n",
    "Criar uma interface interativa usando **Gradio** para processar entrada de texto. O usu√°rio insere um texto e recebe uma resposta processada, podendo ser um simples transformador de texto ou um chatbot.  \n",
    "\n",
    "**O que aprenderemos?**  \n",
    "‚úÖ Como instalar e configurar o Gradio.  \n",
    "‚úÖ Como criar uma interface b√°sica com entrada e sa√≠da de texto.  \n",
    "‚úÖ Como integrar Gradio com uma fun√ß√£o de processamento.  \n",
    "‚úÖ Como compartilhar a aplica√ß√£o na web facilmente.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0bad55c-6771-47c6-b54e-3566c541c31c",
   "metadata": {},
   "source": [
    "# **Importando as bibliotecas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce7b847c-b656-440e-a823-82d11c1445bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Biblioteca para interagir com o sistema operacional e acessar vari√°veis de ambiente\n",
    "import os\n",
    "\n",
    "# Biblioteca para enviar requisi√ß√µes HTTP (como GET e POST) e obter dados da web\n",
    "import requests\n",
    "\n",
    "# BeautifulSoup √© usada para fazer o parsing e extra√ß√£o de dados de HTML (ideal para scraping)\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Tipagem para listas, usada para garantir que vari√°veis sejam listas de tipos espec√≠ficos\n",
    "from typing import List\n",
    "\n",
    "# Biblioteca para carregar vari√°veis de ambiente a partir de arquivos .env\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Biblioteca para intera√ß√£o com a API da OpenAI, incluindo gera√ß√£o de textos com GPT\n",
    "from openai import OpenAI\n",
    "\n",
    "# Gradio √© usado para criar interfaces de usu√°rio interativas de forma simples e r√°pida\n",
    "import gradio as gr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cadcdca9-a7d2-4e02-88a0-d2b939b10fd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A chave de API OpenAI existe e come√ßa sk-proj-\n"
     ]
    }
   ],
   "source": [
    "# Carrega as vari√°veis de ambiente a partir do arquivo .env\n",
    "# O par√¢metro 'override=True' permite sobrescrever vari√°veis j√° carregadas\n",
    "load_dotenv(override=True)\n",
    "\n",
    "# Obt√©m a chave de API do OpenAI da vari√°vel de ambiente\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "# Verifica se a chave de API foi carregada corretamente\n",
    "if openai_api_key:\n",
    "    # Se a chave de API existir, imprime os primeiros 8 caracteres da chave\n",
    "    print(f\"A chave de API OpenAI existe e come√ßa {openai_api_key[:8]}\")\n",
    "else:\n",
    "    # Caso contr√°rio, informa que a chave de API n√£o foi definida\n",
    "    print(\"Chave de API OpenAI n√£o definida\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a7d34a7a-49da-4561-bec4-1994be62c6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Conectando a API da OpenAI, \n",
    "\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc70f737-d935-41bc-9490-a6e35405f8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"Voc√™ √© um assistente √∫til\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d81ba382-3aa7-47ee-a1af-e9930aa1b6d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o que interage com a API do GPT da OpenAI para gerar respostas baseadas em um prompt de usu√°rio\n",
    "def message_gpt(prompt):\n",
    "    # A lista 'messages' cont√©m as mensagens de contexto e do usu√°rio para a intera√ß√£o com o modelo GPT\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},  # Mensagem do sistema, define o comportamento do modelo\n",
    "        {\"role\": \"user\", \"content\": prompt}  # Mensagem do usu√°rio, o prompt que ser√° respondido pelo modelo\n",
    "    ]\n",
    "    \n",
    "    # Envia a requisi√ß√£o para a API da OpenAI, pedindo uma complet√£o com o modelo especificado e as mensagens fornecidas\n",
    "    completion = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',  # Modelo GPT-4 que ser√° utilizado para gerar a resposta\n",
    "        messages=messages,  # Lista de mensagens fornecidas para o modelo\n",
    "    )\n",
    "    \n",
    "    # Retorna o conte√∫do da resposta gerada pelo modelo GPT, extraindo o texto da primeira op√ß√£o retornada\n",
    "    return completion.choices[0].message.content\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9625a107-6fcc-4486-a2fe-f64b5e2f8899",
   "metadata": {},
   "source": [
    "# Hora da interface do usu√°rio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b3215d52-f003-4068-bf04-cc8bf15de299",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o simples que converte o texto para letras mai√∫sculas\n",
    "def shout(text):\n",
    "    # Exibe uma mensagem no console mostrando o texto que foi passado para a fun√ß√£o\n",
    "    print(f\"Shout foi chamado com a entrada {text}\") \n",
    "    \n",
    "    # Retorna o texto convertido para letras mai√∫sculas\n",
    "    return text.upper()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "831de184-e987-489d-b4a3-cc94296433a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7863\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7863/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# A simplicidade do gradio. Isso pode aparecer no \"modo claro\" \n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "132b0226-fa68-4704-a060-5c45bddc6252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7864\n",
      "* Running on public URL: https://b5a70640ba34293fab.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://b5a70640ba34293fab.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionar share=True significa que ele pode ser acessado publicamente\n",
    "# Uma hospedagem mais permanente est√° dispon√≠vel usando uma plataforma chamada Spaces from HuggingFace\n",
    "# NOTA: Alguns softwares antiv√≠rus e firewalls corporativos podem n√£o gostar de voc√™ usar share=True. \n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "316a676e-af77-4f52-8f46-52dbae433231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7865\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7865/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Adicionar inbrowser=True abre uma nova janela do navegador automaticamente\n",
    "\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\").launch(inbrowser=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fe807e-2a6a-4857-8463-b1adfacd8381",
   "metadata": {},
   "source": [
    "## For√ßando o modo escuro\n",
    "\n",
    "Gradio aparece no modo claro ou escuro dependendo das configura√ß√µes do navegador e do computador. Existe uma maneira de for√ßar o gradio a aparecer no modo escuro, mas o Gradio n√£o recomenda isso, pois deve ser uma prefer√™ncia do usu√°rio (principalmente por motivos de acessibilidade). Mas se voc√™ deseja for√ßar o modo escuro em suas telas, veja abaixo como fazer isso.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b399bb-672c-4aa6-83e6-20f9b386fa06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Defina esta vari√°vel e ent√£o passe js=force_dark_mode ao criar a Interface\n",
    "\n",
    "force_dark_mode = \"\"\"\n",
    "function refresh() {\n",
    "    const url = new URL(window.location);\n",
    "    if (url.searchParams.get('__theme') !== 'dark') {\n",
    "        url.searchParams.set('__theme', 'dark');\n",
    "        window.location.href = url.href;\n",
    "    }\n",
    "}\n",
    "\"\"\"\n",
    "gr.Interface(fn=shout, inputs=\"textbox\", outputs=\"textbox\", flagging_mode=\"never\", js=force_dark_mode).launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf57283-bba7-4585-82f9-569c81157156",
   "metadata": {},
   "source": [
    "# Integrando o Gradio ao GPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "25510f17-d664-4cd6-a54a-a5a7d3d4cc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fun√ß√£o que interage com o modelo GPT de forma cont√≠nua (streaming)\n",
    "def stream_gpt(prompt):\n",
    "    # Define a lista de mensagens, incluindo a mensagem do sistema e a entrada do usu√°rio\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_message},\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "\n",
    "    # Envia a solicita√ß√£o para o modelo GPT-4o-mini, ativando o modo de streaming\n",
    "    stream = openai.chat.completions.create(\n",
    "        model='gpt-4o-mini',\n",
    "        messages=messages,\n",
    "        stream=True  # Habilita o streaming de respostas\n",
    "    )\n",
    "\n",
    "    result = \"\"  # Inicializa a vari√°vel para armazenar a resposta gerada\n",
    "\n",
    "    # Itera sobre os blocos de resposta recebidos do modelo\n",
    "    for chunk in stream:\n",
    "        # Adiciona cada novo trecho da resposta ao resultado final\n",
    "        result += chunk.choices[0].delta.content or \"\"\n",
    "\n",
    "        # Utiliza 'yield' para transmitir os dados progressivamente\n",
    "        yield result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1cbc0ff3-2086-4b99-8585-b7e93a23026b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Running on local URL:  http://127.0.0.1:7869\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7869/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Criando a interface do usu√°rio com Gradio\n",
    "view = gr.Interface(\n",
    "    fn=stream_gpt,  # Define a fun√ß√£o que processa a entrada do usu√°rio e retorna a resposta do modelo GPT\n",
    "    inputs=[gr.Textbox(label=\"Your message:\")],  # Campo de entrada de texto para o usu√°rio digitar sua mensagem\n",
    "    outputs=[gr.Markdown(label=\"Response:\")],  # Sa√≠da formatada como Markdown para exibir a resposta do GPT\n",
    "    flagging_mode=\"never\"  # Desativa a op√ß√£o de reportar respostas como inapropriadas\n",
    ")\n",
    "\n",
    "# Inicializa a interface web e a disponibiliza para uso\n",
    "view.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd004b9c-cf53-47f8-be4b-e8176e4e549e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
